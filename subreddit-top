#!/usr/bin/env ruby

require 'json'
require 'nokogiri'
require 'open-uri'
require 'pathname'
require 'rss'

# Required environment variables
begin
  Feed_local_dir = Pathname(ENV['FEED_LOCAL_DIR'])
  Feed_web_dir = Pathname(ENV['FEED_WEB_DIR'])
  Feed_settings_dir = Pathname(ENV['FEED_SETTINGS_DIR'])

  unless Feed_local_dir.directory? &&
         Feed_web_dir &&
         Feed_settings_dir.directory?
    raise Errno::ENOENT
  end
rescue TypeError, Errno::ENOENT
  abort <<~ERROR
    Some required environment variables are not set correctly.
    Full list to verify:

    FEED_LOCAL_DIR: path to directory to read and write feed
    FEED_WEB_DIR: url to web directory hosting the feed
    FEED_SETTINGS_DIR: path to directory containing feed script config files
  ERROR
end

# Configure feed info
site_url = 'https://reddit.com/'
feed_title = 'Subreddit top post amalgamation'
feed_name = 'subreddit-top'

feed_file = Feed_local_dir.join("#{feed_name}.json")
feed_location = Feed_web_dir.join("#{feed_name}.json")

feed = {
  version: 'https://jsonfeed.org/version/1',
  title: feed_title,
  home_page_url: site_url,
  feed_url: feed_location
}

# Leave as is. Preparing the feed.
feed_new = {}
feed_new['items'] = []
feed_old = JSON.parse(feed_file.read) rescue { 'items' => [] }
# DIFFERENT CASE FROM OTHER FEED SCRIPTS, DOES NOT NEED feed_old_first_url

# Strategy for getting new items
Config_file = Feed_settings_dir.join('subreddits.txt')
abort "Missing #{Config_file}" unless Config_file.file?

Check_period = 'week'
Subreddits = Config_file.read.split("\n")
Image_extensions = ['.gif', '.jpg', '.png']
User_agent = 'Ruby script on linux:subreddittop:0.0.1 (no account)'

Subreddits.each do |subreddit|
  warn "Checking #{subreddit}â€¦"
  sleep 3 # Avoid rate limiting

  site_url = 'https://www.reddit.com/r/' + subreddit + '/top.rss?t=' + Check_period + '&limit=1'

  top_item = RSS::Parser.parse(URI.open(site_url, 'User-Agent' => User_agent)).items.first
  item_url = top_item.link.href
  item_title = top_item.title.content

  top_post = lambda {
    data = JSON.parse(URI.open(
      item_url + '.json', 'User-Agent' => User_agent
    ).read).first['data']['children'].first['data']

    {
      text: Nokogiri::HTML.parse(data['selftext_html']),
      url: data['url'],
      video_preview: data.dig('secure_media', 'reddit_video', 'fallback_url') || data.dig('preview', 'reddit_video_preview', 'fallback_url')
    }
  }.call

  content = lambda {
    html = []
    html.push('<p>From r/' + subreddit + '</p>')
    html.push(top_post[:text]) unless top_post[:text].nil?

    return html if top_post[:url] == item_url

    # If post is video, embed it
    if top_post[:video_preview]
      html.push('<video><source src="' + top_post[:video_preview] + '"></video>')
      return html
    end

    # If post is image, embed it
    if Image_extensions.any? { |ext| Pathname(top_post[:url]).extname == ext }
      html.push('<img src="' + top_post[:url] + '">')
      return html
    end

    html.push('<a href="' + top_post[:url] + '">' + top_post[:url] + '</a>')

    html
  }.call.join

  feed_new['items'].push(title: item_title, id: item_url, url: item_url, content_html: content)
end

# If there are no new items, inform and exit
if feed_new['items'].empty?
  puts 'There are no new items to add'
  exit 0
end

# Prepend new items to the old and limit the amount of items
feed['items'] = (feed_new['items'] + feed_old['items']).first(100)

feed_file.write(JSON.pretty_generate(feed))
